training.per=c(start(GSPC),index(GSPC["1999-12-31"])),
ntree=50, importance=T)
library(DMwR)
library(randomForest)
data(GSPC)
data.model <- specifyModel(T.ind(GSPC) ~ Delt(Cl(GSPC),k=1:10) +
myATR(GSPC) + mySMI(GSPC) + myADX(GSPC) + myAroon(GSPC) +
myBB(GSPC)  + myChaikinVol(GSPC) + myCLV(GSPC) +
CMO(Cl(GSPC)) + EMA(Delt(Cl(GSPC))) + myEMV(GSPC) +
myVolat(GSPC)  + myMACD(GSPC) + myMFI(GSPC) + RSI(Cl(GSPC)) +
mySAR(GSPC) + runMean(Cl(GSPC)) + runSD(Cl(GSPC)))
set.seed(1234)
rf <- buildModel(data.model,method='randomForest',
training.per=c(start(GSPC),index(GSPC["1999-12-31"])),
ntree=50, importance=T)
###################################################
### Load Data
###################################################
library(xts)
StockData <- as.xts(read.zoo("sp500.csv", header=T))
###################################################
### Defining the Prediction Tasks
###################################################
library(quantmod)
T.ind <- function(quotes, tgt.margin = 0.025, n.days = 10) {
v <- apply(HLC(quotes), 1, mean)
r <- matrix(NA, ncol = n.days, nrow = NROW(quotes))
for (x in 1:n.days) r[,x] <- Next(Delt(v, k =x), x)
x <- apply(r, 1, function(x) sum(x[x > tgt.margin | x <
-tgt.margin]))
if (is.xts(quotes))
xts(x, time(quotes))
else x
}
###################################################
### Plot Prediction Indicator
###################################################
candleChart(last(StockData, "3 months"), theme = "white", TA = NULL)
avgPrice <- function(p) apply(HLC(p), 1, mean)
addAvgPrice <- newTA(FUN = avgPrice, col = 1, legend = "AvgPrice")
addT.ind <- newTA(FUN = T.ind, col = "red", legend = "tgtRet")
addAvgPrice(on = 1)
addT.ind()
###################################################
### Representative set of technical indicator
### to choose from
###################################################
myATR <- function(x) ATR(HLC(x))[,'atr']
mySMI <- function(x) SMI(HLC(x))[,'SMI']
myADX <- function(x) ADX(HLC(x))[,'ADX']
myAroon <- function(x) aroon(x[,c('High','Low')])$oscillator
myBB <- function(x) BBands(HLC(x))[,'pctB']
myChaikinVol <- function(x) Delt(chaikinVolatility(x[,c("High","Low")]))[,1]
myCLV <- function(x) EMA(CLV(HLC(x)))[,1]
myEMV <- function(x) EMV(x[,c('High','Low')],x[,'Volume'])[,2]
myMACD <- function(x) MACD(Cl(x))[,2]
myMFI <- function(x) MFI(x[,c("High","Low","Close")], x[,"Volume"])
mySAR <- function(x) SAR(x[,c('High','Close')]) [,1]
myVolat <- function(x) volatility(OHLC(x),calc="garman")[,1]
###################################################
### Estimate most important features
### using Random Forests
###################################################
library(DMwR)
library(randomForest)
data(GSPC)
data.model <- specifyModel(T.ind(GSPC) ~ Delt(Cl(GSPC),k=1:10) +
myATR(GSPC) + mySMI(GSPC) + myADX(GSPC) + myAroon(GSPC) +
myBB(GSPC)  + myChaikinVol(GSPC) + myCLV(GSPC) +
CMO(Cl(GSPC)) + EMA(Delt(Cl(GSPC))) + myEMV(GSPC) +
myVolat(GSPC)  + myMACD(GSPC) + myMFI(GSPC) + RSI(Cl(GSPC)) +
mySAR(GSPC) + runMean(Cl(GSPC)) + runSD(Cl(GSPC)))
set.seed(1234)
rf <- buildModel(data.model,method='randomForest',
training.per=c(start(GSPC),index(GSPC["1999-12-31"])),
ntree=50, importance=T)
###################################################
### Load Data
###################################################
library(xts)
StockData <- as.xts(read.zoo("sp500.csv", header=T))
###################################################
### Defining the Prediction Tasks
###################################################
library(quantmod)
T.ind <- function(quotes, tgt.margin = 0.025, n.days = 10) {
v <- apply(HLC(quotes), 1, mean)
r <- matrix(NA, ncol = n.days, nrow = NROW(quotes))
for (x in 1:n.days) r[,x] <- Next(Delt(v, k =x), x)
x <- apply(r, 1, function(x) sum(x[x > tgt.margin | x <
-tgt.margin]))
if (is.xts(quotes))
xts(x, time(quotes))
else x
}
###################################################
### Plot Prediction Indicator
###################################################
candleChart(last(StockData, "3 months"), theme = "white", TA = NULL)
avgPrice <- function(p) apply(HLC(p), 1, mean)
addAvgPrice <- newTA(FUN = avgPrice, col = 1, legend = "AvgPrice")
addT.ind <- newTA(FUN = T.ind, col = "red", legend = "tgtRet")
addAvgPrice(on = 1)
addT.ind()
demo()
graphics
demo(graphics)
demo(image)
demo(Japanese)
demo(plotmath)
sd(c(5,8,12))
which.min(c(4,1,6))
rattle()
library(rattle)
rattle()
install.packages('shiny')
library(shiny)
?shiny
install.packages(c("amap", "arules", "arulesViz", "boot", "cairoDevice", "chron", "class", "cluster", "e1071", "effects", "evaluate", "foreign", "gridBase", "gtools", "Hmisc", "httpuv", "igraph", "KernSmooth", "lava", "lme4", "maptools", "MASS", "Matrix", "multcomp", "nlme", "nnet", "plotrix", "plyr", "pROC", "psych", "rattle", "Rcpp", "RGtk2", "rms", "rpart", "RWeka", "scatterplot3d", "seriation", "spam", "spatial", "testthat", "tree", "xtable"))
install.packages(c("RWeka", "scatterplot3d", "seriation", "spam", "spatial", "testthat", "tree", "xtable"))
library(ggplot2)
“ggplot(data = diamonds) + geom_histogram(aes(x = carat))”
ggplot(data = diamonds) + geom_histogram(aes(x = carat))
g <- ggplot(diamonds, aes(x = carat, y = price))
g + geon_point(aes(color = color))
g + geom_point(aes(color = color))
require(devtools)
install_github('rCharts', 'ramnathv')
require(devtools)
install.packages("devtools")
install_github('rCharts', 'ramnathv')
library(devtools)
install_github('rCharts', 'ramnathv')
library(rCharts)
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
hair_eye = as.data.frame(HairEyeColor)
rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
hair_eye_male <- subset(as.data.frame(HairEyeColor), Sex == "Male")
n1 <- nPlot(Freq ~ Hair, group = "Eye", data = hair_eye_male, type = "multiBarChart")
n1$print("chart3")
map3 <- Leaflet$new()
map3$setView(c(51.505, -0.09), zoom = 13)
map3$marker(c(51.5, -0.09), bindPopup = "<p> Hi. I am a popup </p>")
map3$marker(c(51.495, -0.083), bindPopup = "<p> Hi. I am another popup </p>")
map3$print("chart7")
library(MASS)
?MASS
??MASS
install.packages(c("car", "caTools", "cluster", "devtools", "evaluate", "foreach", "gdata", "gplots", "gtools", "Hmisc", "httpuv", "igraph", "iterators", "lattice", "lme4", "markdown", "MASS", "Matrix", "memoise", "mgcv", "multcomp", "mvtnorm", "nlme", "pROC", "psych", "reshape", "reshape2", "RJSONIO", "rms", "RWeka", "RWekajars", "scales", "slam", "sp", "verification"))
install.packages("Shiny")
install.packages("shiny")
install.packages("rmarkdown")
install.packages("knitr")
install.packages("ISLR")
require(ISLR)
require(boot)
plot(mpg~horsepower, data=Auto)
glm.fit = glm(mpg~horsepower, data=Auto)
cv.glm(Auto, glm.git)$delta
cv.glm(Auto, glm.fit)$delta
setwd("~/Projects/practice/test")
library('ProjectTemplate')
create.project('letters')
require(twitteR)
rdmTweets <- searchTwitter('#mozfest', n=500)
getwd()
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="cacert.pem")
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "F5eWLl9QE9hkJdufOS5mHLNqU"
consumerSecret <- "UBpjrgUvGa5yWX2cgF4TayZAqWydVirXDdXOQUD6FFdu3pKyUE"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
save(list="twitCred", file="twitteR_credentials")
library(twitteR)
load("twitteR_credentials")
registerTwitterOAuth(twitCred)
s <- searchTwitter('#Subisu', cainfo="cacert.pem")
s
s <- searchTwitter('@subisu', cainfo="cacert.pem")
s
s <- searchTwitter('#ncell', cainfo="cacert.pem")
s
s <- searchTwitter('#subisu', cainfo="cacert.pem", n=100)
s <- searchTwitter('@subisu', cainfo="cacert.pem", n=100)
s
s <- searchTwitter('@Subisu', cainfo="cacert.pem", n=100)
s
s <- searchTwitter('@sauravD', cainfo="cacert.pem", n=100)
s
s <- searchTwitter(“@airtel_presence”,n=1500)
s <- searchTwitter("@airtel_presence",n=1500)
head(s)
s <- searchTwitter('@subisu', cainfo="cacert.pem", n=100)
subisu.tweets <- searchTwitter('@subisu', cainfo="cacert.pem", n=100)
length(subisu.tweets)
class(subisu.tweets)
class(subisu.tweets[[1]])
subisu.tweets[[1]]
aTweet = subisu.tweets[[1]]
aTweet
aTweet
user <-getUser("subisu", cainfo="cacert.pem")
user
user$created
user$location
user$statusesCount
user$followersCount
user$lastStatus
user$friendsCount
library(plyr)
tweets.df = ldply(subisu.tweets, function(t) t$toDataFrame() )
summary(tweets.df)
write.csv(tweets.df, file = "subisutweets.csv")
library(XML)
subisu.tweets <- searchTwitter('@ncell', cainfo="cacert.pem", n=100)
length(subisu.tweets)
class(subisu.tweets)
class(subisu.tweets[[1]])
subisu.tweets[[1]]
subisu.tweets
library(twitteR)
load("twitteR_credentials")
registerTwitterOAuth(twitCred)
tweets <- searchTwitter('@ncell', cainfo="cacert.pem", n=100)
head(tweets)
head(tweets, 10)
tweets <- searchTwitter('@wlink', cainfo="cacert.pem", n=100)
tweets <- searchTwitter('@subisu', cainfo="cacert.pem", n=100)
head(tweets, 10)
install.packages("swirl")
library(swirl)
swirl()
install.packages("MASS")
installed.packages()
library()
install.packages(ggplot2)
install.packages('ggplot2')
install.packages('data.table')
install.packages('plyr')
install.packages('stringr')
install.packages('reshape2')
install.packages('lubridate')
install.packages('randomForest')
install.packages('rpart')
install.packages('rpart.plot')
install.packages('stringr')
install.packages('caret')
install.packages('knitr')
install.packages('scales')
install.packages('car')
install.packages('digest')
install.packages('colorspace')
install.packages('RColorBrewer')
install.packages('zoo')
install.packages('Hmisc')
install.packages('e1071')
install.packages('lmtest')
install.packages('survival')
install.packages('quadprog')
install.packages('kohonen')
install.packages('maps')
install.packages('RCurl')
install.packages('caTools')
install.packages('ROCR')
install.packages('igraph')
install.packages('maptools')
install.packages('markdown')
install.packages('RJSONIO')
install.packages('forecast')
install.packages('devtools')
install.packages('foreign')
install.packages('glmnet')
install.packages('gbm')
install.packages('xlsx')
install.packages('xts')
install.packages('Rcpp')
install.packages('parallel')
install.packages('proto')
install.packages('bayesm')
install.packages('arules')
install.packages('formatR')
install.packages('party')
install.packages()
library()
manipulate()
install.packages('manipulate')
install.packages('manipulate')
library(ISLR)
fix(Hitters)
Hitters=na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
library(leaps)
isntall.packages(leaps)
install.packages(leaps)
install.packages('leaps')
library(leaps)
regfit.full = regsubsets(Salary~.,Hitters)
summary(regfit.full)
regfit.full = regsubsets(Salary~.,Hitters, nvmax=19)
summary(regfit.full)
reg.summary=summary(regfit.full)
names(reg.summary)
reg.summary$rsq
par(mfrow=c(2,2))
plot(reg.summary$rss, xlab="Number of Variables", ylab="RSS", type="l")
plot(reg.summary$adjr2, xlab="Number of Variables", ylab="Adj. Rsq", type="l")
which.max(reg.summary$adjr2)
points(11,reg.summary$adjr2[11], col="red", cex=2, pch=20)
plot(regfit.full, scale="r2")
par(mfrow=c(1,1))
plot(regfit.full, scale="r2")
x = model.matrix(Salary~.,Hitters)[-1]
y = Hitters$Salary
library(glmnet)
grid=10^2seq(10,-2,length=100)
grid=10^seq(10,-2,length=100)
ridge.mod = glmnet(x,y,alpha=0,lambda=grid)
x = model.matrix(Salary~.,Hitters)[,-1]
ridge.mod = glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
install.packages('pls')
library(splines)
library(gam)
install.packages('gam')
library(raster)
library(maptools)
library(rgdal)
library(animation)
library(RColorBrewer)
malb<-getData("GADM", country="NEP", level=1)
malb<-getData("GADM", country="NPL", level=1)
malp<-getData("worldclim", var="prec", res=0.5, lon=85, lat=27)
malpe<-extract(wmap,malb,fun=mean, na.rm=T)
malpe<-data.frame(malpe)
malb@data<-malpe
dat<-colnames(malb@data)
malb@data$id<-row.names(malb@data)
malbf<-fortify(malb, region="id")
malb.df<-merge(malbf,malb@data, by="id")
colnames(malb.df)[8:19]<-c("January","February","March","April","May","June","July","August","September","October","November","December")
col<-brewer.pal(9,"Spectral")
for (i in 8:19){
var<-colnames(malb.df)[i]
p<-ggplot(malb.df, aes(long,lat, group=group))+geom_polygon(aes_string(fill=var))+coord_equal()
p<-p+geom_polygon(data=malb, aes(long,lat.group=group),fill=NA, colour="black")
p<-p+scale_fill_gradientn("Rainfall",limits=c(0,330),guide="legend", breaks=seq(0,330,30), colours=col)
p<-p+theme_bw()+ggtitle(var)
print(p)
ggsave(file=paste("pr",i,".png", sep=""))
}
files = sprintf('pr%d.png', 8:19)
im.convert(files, output = 'Rainfall.gif')
malpe<-extract(wmap,malb,fun=mean, na.rm=T)
malpe<-extract(malp,malb,fun=mean, na.rm=T)
library(leafletR)
library(rgdal)
library(rgeos)
library(sp)
require(devtools)
install_github('ramnathv/rCharts@dev')
library(Quandl)
install.packages('Quandl')
library(Quandl)
vcData = Quandl("FBI_UCR/USCRIME_TYPE_VIOLENTCRIMERATE")
kable(head(vcData[,1:9]), format = 'html', table.attr = "class=nofluid")
?kable
require(knitr)
kable(head(vcData[,1:9]), format = 'html', table.attr = "class=nofluid")
library(reshape2)
datm <- melt(vcData, 'Year',
variable.name = 'State',
value.name = 'Crime'
)
datm <- subset(na.omit(datm),
!(State %in% c("United States", "District of Columbia"))
)
kable(head(datm), format = 'html', table.attr = "class=nofluid")
datm2 <- transform(datm,
State = state.abb[match(as.character(State), state.name)],
fillKey = cut(Crime, quantile(Crime, seq(0, 1, 1/5)), labels = LETTERS[1:5]),
Year = as.numeric(substr(Year, 1, 4))
)
kable(head(datm2), format = 'html', table.attr = "class=nofluid")
fills = setNames(
c(RColorBrewer::brewer.pal(5, 'YlOrRd'), 'white'),
c(LETTERS[1:5], 'defaultFill')
)
library(plyr); library(rMaps)
dat2 <- dlply(na.omit(datm2), "Year", function(x){
y = toJSONArray2(x, json = F)
names(y) = lapply(y, '[[', 'State')
return(y)
})
require(rCharts)
library(plyr); library(rMaps)
dat2 <- dlply(na.omit(datm2), "Year", function(x){
y = toJSONArray2(x, json = F)
names(y) = lapply(y, '[[', 'State')
return(y)
})
options(rcharts.cdn = TRUE)
map <- Datamaps$new()
map$set(
dom = 'chart_1',
scope = 'usa',
fills = fills,
data = dat2[[1]],
legend = TRUE,
labels = TRUE
)
map
map2 = map$copy()
map2$set(
bodyattrs = "ng-app ng-controller='rChartsCtrl'"
)
map2$addAssets(
jshead = "http://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.1/angular.min.js"
)
map2$setTemplate(chartDiv = "
<div class='container'>
<input id='slider' type='range' min=1960 max=2010 ng-model='year' width=200>
<span ng-bind='year'></span>
<div id='' class='rChart datamaps'></div>
</div>
<script>
function rChartsCtrl($scope){
$scope.year = 1960;
$scope.$watch('year', function(newYear){
map.updateChoropleth(chartParams.newData[newYear]);
})
}
</script>"
)
map2$set(newData = dat2)
map2
install.packages("rjags")
library(ggmap)
qmap("Harvard University", zoom = 14, source = "stamen")
qmap("Harvard University", zoom = 14, source = "stamen", maptype = "watercolor")
qmap("Harvard University", zoom = 14, source = "stamen", maptype = "toner")
qmap("Kathmandu Valley", zoom = 14, source = "stamen", maptype = "toner")
qmap("Kathmandu Valley", zoom = 13, source = "stamen", maptype = "toner")
qmap("Kathmandu Valley", zoom = 13, source = "stamen", maptype = "toner")
qmap("Kathmandu Valley", zoom = 12, source = "stamen", maptype = "toner")
qmap("Kathmandu Valley", zoom = 12, source = "stamen", maptype = "watercolor")
qmap("Kathmandu Valley", zoom = 12, source = "stamen", maptype = "watercolor")
qmap("Kathmandu Valley", zoom = 12, source = "google")
qmap("Kathmandu City", zoom = 13, source = "google")
qmap("Kathmandu City", zoom = 13, source = "stamen")
require(ggvis)
help(ggvis)
mtcars %>% ggvis(~mpg, ~wt)
mtcars %>% ggvis(~mpg, ~wt, fill = ~cyl)
mtcars %>% ggvis(~mpg, ~wt, fill := "red")
mtcars %>% ggvis(~mpg)
layer_points(ggvis(mtcars, ~mpg, ~wt))
mtcars %>%
ggvis(~mpg, ~wt) %>%
layer_points() %>%
layer_smooths()
require(arules)
require(arulesViz)
require(datasets)
data(Groceries)
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
# Visualization
plot(rules,method="graph",interactive=TRUE,shading=NA)
install.packages(c("animation", "arules", "base64enc", "class", "Formula", "ggvis", "gplots", "httr", "leafletR", "lme4", "markdown", "mgcv", "mime", "mvtnorm", "party", "randomForest", "RCurl", "rgeos", "RJSONIO", "sandwich", "shiny", "TSP"))
install.packages("party")
install.packages("partykit")
install.packages("htmlwidgets")
install.packages(c("arules", "arulesViz", "BH", "car", "caret", "digest", "diptest", "forecast", "gplots", "Hmisc", "httr", "jsonlite", "knitr", "magrittr", "manipulate", "mgcv", "mvtnorm", "party", "partykit", "plotrix", "Quandl", "R6", "RColorBrewer", "RcppEigen", "RCurl", "reshape2", "rjags", "rjson", "robustbase", "rpart.plot", "seriation", "shiny", "sp", "timeDate"))
library(xlsx)
install.packages(c("BH", "manipulate"))
install.packages("sparkTable")
install.packages(c("car", "cluster", "dismo", "gstat", "manipulate", "raster", "Rcpp", "RgoogleMaps", "spacetime", "timeDate"))
setwd("~/projects/dataviz/Republica_Federalsm")
library("reshape2")
header=T)
h=True)
nepal_districts <- read.csv("data/District wise Population Land Ratio and Population Density_0.csv")
head(nepal_districts)
str(nepal_districts)
wide <- dcast(nepal_districts, district ~ Category)
wide <- dcast(nepal_districts, District ~ Category)
head(wide)
write.csv("district_pop.csv");
write.csv("district_pop.csv")
?write.csv
write.csv(nepal_districts, file = "district_pop.csv")
setwd("~/projects/dataviz/Republica_Federalsm/Data")
library("reshape2")
nepal_districts <- read.csv("data/District wise Population Land Ratio and Population Density_0.csv")
nepal_districts <- read.csv("District wise Population Land Ratio and Population Density_0.csv")
head(nepal_districts)
str(nepal_districts)
wide <- dcast(nepal_districts, District ~ Category)
write.csv(wide, file = "district_pop.csv")
